{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import LinearNDInterpolator\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from time import time\n",
    "import os\n",
    "import netCDF4 as nc\n",
    "from time import time\n",
    "from progressbar import progressbar\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read CYGNSS data\n",
    "def calculate_sr_value(snr, p_r, g_t, g_r, d_ts, d_sr):\n",
    "    return snr - p_r - g_t - g_r - (20 * np.log10(0.19)) + (20 * np.log10(d_ts + d_sr)) + (20 * np.log10(4 * np.pi))\n",
    "\n",
    "\n",
    "def compute_surface_reflectivity(df):\n",
    "    df['sr'] = df.apply(\n",
    "        lambda row: calculate_sr_value(row.ddm_snr, row.gps_tx_power_db_w, row.gps_ant_gain_db_i, row.sp_rx_gain,\n",
    "                                       row.tx_to_sp_range, row.rx_to_sp_range), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def calculate_hours_after_jan_value(day_of_year, ddm_timestamp):\n",
    "    return (day_of_year - 1) * 24 + ddm_timestamp / (60 * 60)\n",
    "\n",
    "\n",
    "def compute_hours_after_jan(df):\n",
    "    df['hours_after_jan_2020'] = df.apply(\n",
    "        lambda row: calculate_hours_after_jan_value(row.day_of_year, row.ddm_timestamp_utc), axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_cygnss_df(df: pd.DataFrame, area: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters cygnss dataframe\n",
    "    :param df: pd.Dataframe\n",
    "    :param area: [N, W, S, E]\n",
    "    :return: pd.Dataframe\n",
    "    \"\"\"\n",
    "    new_df = df[df['sp_lat'] < area[0]]\n",
    "    new_df = new_df[new_df['sp_lat'] > area[2]]\n",
    "    new_df = new_df[new_df['sp_lon'] > area[1]]\n",
    "    new_df = new_df[new_df['sp_lon'] < area[3]]\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def fuzzy_filter_cygnss_df(df: pd.DataFrame, area: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Filters cygnss dataframe for a 10 degrees larger area than the input\n",
    "    :param df: pd.Dataframe\n",
    "    :param area: [N, W, S, E]\n",
    "    :return: pd.Dataframe\n",
    "    \"\"\"\n",
    "    new_df = df[df['sp_lat'] < area[0] + 10]\n",
    "    new_df = new_df[new_df['sp_lat'] > area[2] - 10]\n",
    "    new_df = new_df[new_df['sp_lon'] > area[1] - 10]\n",
    "    new_df = new_df[new_df['sp_lon'] < area[3] + 10]\n",
    "\n",
    "    return new_df\n",
    "\n",
    "\n",
    "def get_cygnss_df(cygnss_root_path: str, days: list, area: list, fuzzy_filter=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    If you want 1st to 3rd of August, days should be [1, 2, 3]\n",
    "    :param cygnss_root_path: path to the root folder with cygnss data\n",
    "    :param days: days list, e.g. [1, 2, 3]\n",
    "    :param area: [N, W, S, E]\n",
    "    :param fuzzy_filter: boolean. Whether or not to use fuzzy filter.\n",
    "    :return: pd.Dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    file_start = 'raw_main_df_2020_08_'\n",
    "    file_ending = 'of31.csv'\n",
    "\n",
    "    cygnss_df = pd.DataFrame()\n",
    "\n",
    "    for day in days:\n",
    "        current_path = cygnss_root_path + file_start + str(day) + file_ending\n",
    "        if fuzzy_filter:\n",
    "            current_cygnss_df = compute_surface_reflectivity(fuzzy_filter_cygnss_df(pd.read_csv(current_path), area))\n",
    "        else:\n",
    "            current_cygnss_df = compute_surface_reflectivity(filter_cygnss_df(pd.read_csv(current_path), area))\n",
    "        current_cygnss_df = compute_hours_after_jan(current_cygnss_df)\n",
    "        cygnss_df = cygnss_df.append(current_cygnss_df)\n",
    "\n",
    "    return cygnss_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to read SMAP data\n",
    "def get_smap(path: str, printing=False):\n",
    "    ds = nc.Dataset(path)\n",
    "    sm = ds['Soil_Moisture_Retrieval_Data_AM']\n",
    "\n",
    "    latitudes = []\n",
    "    longitudes = []\n",
    "    moistures = []\n",
    "    times = []\n",
    "    qfs = []\n",
    "    landcover_01 = []\n",
    "    landcover_02 = []\n",
    "    landcover_03 = []\n",
    "    roughness = []\n",
    "    surface_temp = []\n",
    "    vo = []\n",
    "    veg_wat_cont = []\n",
    "\n",
    "    for lat in progressbar(range(len(sm['latitude']))):\n",
    "        for long in range(len(sm['longitude'][lat])):\n",
    "            latitudes.append(sm['latitude'][lat][long])\n",
    "            longitudes.append(sm['longitude'][lat][long])\n",
    "            moistures.append(sm['soil_moisture'][lat][long])\n",
    "            times.append(sm['tb_time_utc'][lat][long])\n",
    "            qfs.append(sm['retrieval_qual_flag'][lat][long])\n",
    "            landcover_01.append(sm['landcover_class.Bands_01'][lat][long])\n",
    "            landcover_02.append(sm['landcover_class.Bands_02'][lat][long])\n",
    "            landcover_03.append(sm['landcover_class.Bands_03'][lat][long])\n",
    "            roughness.append(sm['roughness_coefficient'][lat][long])\n",
    "            surface_temp.append(sm['surface_temperature'][lat][long])\n",
    "            vo.append(sm['vegetation_opacity'][lat][long])\n",
    "            veg_wat_cont.append(sm['vegetation_water_content'][lat][long])\n",
    "\n",
    "    # df = pd.DataFrame.from_dict({'lat': latitudes, 'long': longitudes, 'time': times, 'smap_sm': moistures})\n",
    "    df = pd.DataFrame.from_dict({'lat': latitudes, 'long': longitudes, 'time': times, 'smap_sm': moistures,\n",
    "                                 'retrieval_qfs': qfs, 'surface_roughness': roughness,\n",
    "                                 'surface_temp': surface_temp, 'vegetation_opacity': vo,\n",
    "                                 'vegetation_water_content': veg_wat_cont, 'landcover_class_01': landcover_01,\n",
    "                                 'landcover_class_02': landcover_02, 'landcover_class_03': landcover_03})\n",
    "\n",
    "    # Filter out missing values\n",
    "    smap_df = df[df['smap_sm'] != -9999.0]\n",
    "\n",
    "    if len(smap_df) > 0 and printing:\n",
    "        print('Number of missing values:', len(df) - len(smap_df))\n",
    "        print('Number of data points with value:', len(smap_df))\n",
    "        index = list(smap_df['smap_sm']).index(max(list(smap_df['smap_sm'])))\n",
    "        print(\"Peak SM value:\", list(smap_df['smap_sm'])[index])\n",
    "        print(\"Peak SM value at: (\" + str(list(smap_df['lat'])[index]) + \", \" + str(list(smap_df['long'])[index]) + \")\")\n",
    "\n",
    "    return smap_df\n",
    "\n",
    "\n",
    "def conv(t):\n",
    "    try:\n",
    "        return pd.Timestamp(t)\n",
    "    except:\n",
    "        return pd.Timestamp(t.split('.')[0] + '.000Z')\n",
    "\n",
    "\n",
    "def convert_time(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ref_date = pd.Timestamp('2020-01-01T00:00:00.000Z')\n",
    "\n",
    "    df['time'] = df['time'].apply(lambda t: conv(t))\n",
    "    df['time'] = df['time'].apply(lambda t: (t - ref_date).days * 24 + (t - ref_date).seconds / 3600)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_smap_df(root_dir: str, year: int, convert_time_hours=True) -> pd.DataFrame:\n",
    "    first = True\n",
    "    all_paths = []\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if not first:\n",
    "                all_paths.append(os.path.join(subdir, file))\n",
    "            else:\n",
    "                first = False\n",
    "\n",
    "    smap_df = pd.DataFrame()\n",
    "\n",
    "    for path in all_paths:\n",
    "        path_split = path.split('_')\n",
    "        current_year = int(path_split[4][:4])\n",
    "\n",
    "        if current_year == year:\n",
    "            current_df = get_smap(path)\n",
    "            smap_df = smap_df.append(current_df)\n",
    "\n",
    "    if convert_time_hours:\n",
    "        smap_df = convert_time(smap_df)\n",
    "\n",
    "    return smap_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for the main program\n",
    "def create_interval_list(interval: int, min_value: int, max_value: int) -> list:\n",
    "    interval_list = []\n",
    "\n",
    "    while min_value <= max_value:\n",
    "        interval_list.append(min_value)\n",
    "        min_value += interval\n",
    "\n",
    "    return interval_list\n",
    "\n",
    "def interpolate(df: pd.DataFrame, target_value, lat_name='lat', long_name='long',\n",
    "                time_name='time') -> LinearNDInterpolator:\n",
    "    coordinates = list(zip(list(df[time_name]), list(df[lat_name]), list(df[long_name])))\n",
    "    target = df[target_value]\n",
    "    interpolation_function = LinearNDInterpolator(coordinates, target)\n",
    "    return interpolation_function\n",
    "\n",
    "def filter_nan_smap(df, target='sm'):\n",
    "    try:\n",
    "        df[target] = df[target].apply(lambda x: x.item(0))\n",
    "    except:\n",
    "        print('SMAP_SM value was already of type: float')\n",
    "    df = df.dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables\n",
    "target_val = 'sp_inc_angle'\n",
    "cygnss_root_path = \"/Volumes/DACOTA HDD/Semester Project CSV/CYGNSS 2020-08/\"\n",
    "smap_root_path = \"/Users/vegardhaneberg/Desktop/Masters Thesis/Code/Master/Data/SMAP/India first two weeks of August\"\n",
    "days = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "#      [  N     W      S      E]\n",
    "area = [27.2, 80.32, 21.81, 88.29]\n",
    "interval = 20\n",
    "min_value = 0\n",
    "max_value = 60\n",
    "fuzzy = False\n",
    "step_size = 2\n",
    "incidence_classes = list(range(min_value, max_value, step_size))\n",
    "statistics_dict = {}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Volumes/DACOTA HDD/Semester Project CSV/CYGNSS 2020-08/raw_main_df_2020_08_1of31.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/11/0v6dl9dd455c1b47f6bgcq4c0000gp/T/ipykernel_85474/2028154888.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Read CYGNSS\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mstart\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mcygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_cygnss_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcygnss_root_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdays\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marea\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfuzzy_filter\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfuzzy\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'Done reading '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcygnss_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m' CYGNSS items in '\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mround\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mstart\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m' sec'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/11/0v6dl9dd455c1b47f6bgcq4c0000gp/T/ipykernel_85474/2123286107.py\u001B[0m in \u001B[0;36mget_cygnss_df\u001B[0;34m(cygnss_root_path, days, area, fuzzy_filter)\u001B[0m\n\u001B[1;32m     71\u001B[0m             \u001B[0mcurrent_cygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_surface_reflectivity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfuzzy_filter_cygnss_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marea\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 73\u001B[0;31m             \u001B[0mcurrent_cygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_surface_reflectivity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilter_cygnss_df\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0marea\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     74\u001B[0m         \u001B[0mcurrent_cygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcompute_hours_after_jan\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_cygnss_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     75\u001B[0m         \u001B[0mcygnss_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcygnss_df\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcurrent_cygnss_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/util/_decorators.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    309\u001B[0m                     \u001B[0mstacklevel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstacklevel\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    310\u001B[0m                 )\n\u001B[0;32m--> 311\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    312\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    313\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    584\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    585\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 586\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    587\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    588\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    480\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 482\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    483\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    484\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    809\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 811\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    812\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    813\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1038\u001B[0m             )\n\u001B[1;32m   1039\u001B[0m         \u001B[0;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1040\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1041\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1042\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     50\u001B[0m         \u001B[0;31m# open handles\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 51\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     52\u001B[0m         \u001B[0;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     53\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001B[0m in \u001B[0;36m_open_handles\u001B[0;34m(self, src, kwds)\u001B[0m\n\u001B[1;32m    220\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHandles\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    221\u001B[0m         \"\"\"\n\u001B[0;32m--> 222\u001B[0;31m         self.handles = get_handle(\n\u001B[0m\u001B[1;32m    223\u001B[0m             \u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    224\u001B[0m             \u001B[0;34m\"r\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/opt/anaconda3/envs/gnssr/lib/python3.9/site-packages/pandas/io/common.py\u001B[0m in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    700\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mencoding\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0;34m\"b\"\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    701\u001B[0m             \u001B[0;31m# Encoding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 702\u001B[0;31m             handle = open(\n\u001B[0m\u001B[1;32m    703\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    704\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/Volumes/DACOTA HDD/Semester Project CSV/CYGNSS 2020-08/raw_main_df_2020_08_1of31.csv'"
     ]
    }
   ],
   "source": [
    "# Read CYGNSS\n",
    "start = time()\n",
    "cygnss_df = get_cygnss_df(cygnss_root_path, days, area, fuzzy_filter=fuzzy)\n",
    "print('Done reading ' + str(len(cygnss_df)) + ' CYGNSS items in ' + str(round(time() - start, 0)) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read SMAP\n",
    "start = time()\n",
    "smap_df = get_smap_df(smap_root_path, 2020, convert_time_hours=True)\n",
    "print('Done reading ' + str(len(smap_df)) + ' SMAP items in ' + str(round(time() - start, 0)) + ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_statistics(smap_df, cygnss_df):\n",
    "    smap_lat_min = smap_df['lat'].min()\n",
    "    smap_lat_max = smap_df['lat'].max()\n",
    "    smap_long_min = smap_df['long'].min()\n",
    "    smap_long_max = smap_df['long'].max()\n",
    "    smap_time_min = smap_df['time'].min()\n",
    "    smap_time_max = smap_df['time'].max()\n",
    "\n",
    "    print('SMAP items:', len(smap_df))\n",
    "    print('SMAP lat min:', smap_lat_min)\n",
    "    print('SMAP lat max:', smap_lat_max)\n",
    "    print('SMAP long min:', smap_long_min)\n",
    "    print('SMAP long max:', smap_long_max)\n",
    "    print('SMAP time min:', smap_time_min)\n",
    "    print('SMAP time max:', smap_time_max)\n",
    "    print('\\n')\n",
    "    print(\"CYGNSS items:\", len(cygnss_df))\n",
    "    print('CYGNSS lat min:', cygnss_df['sp_lat'].min())\n",
    "    print('CYGNSS lat max:', cygnss_df['sp_lat'].max())\n",
    "    print('CYGNSS long min:', cygnss_df['sp_lon'].min())\n",
    "    print('CYGNSS long max:', cygnss_df['sp_lon'].max())\n",
    "    print('CYGNSS time min:', cygnss_df['hours_after_jan_2020'].min())\n",
    "    print('CYGNSS time max:', cygnss_df['hours_after_jan_2020'].max())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cygnss_df = cygnss_df[cygnss_df['sp_lat'] > smap_lat_min]\n",
    "# cygnss_df = cygnss_df[cygnss_df['sp_lat'] < smap_lat_max]\n",
    "# cygnss_df = cygnss_df[cygnss_df['sp_lon'] > smap_long_min]\n",
    "# cygnss_df = cygnss_df[cygnss_df['sp_lon'] < smap_long_max]\n",
    "# cygnss_df = cygnss_df[cygnss_df['hours_after_jan_2020'] > smap_time_min]\n",
    "# cygnss_df = cygnss_df[cygnss_df['hours_after_jan_2020'] < smap_time_max]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate soil moisture, vegetation opacity and surface roughness\n",
    "inter_function_inc = interpolate(smap_df, 'smap_sm', 'lat', 'long', 'time')\n",
    "cygnss_df['sm'] = cygnss_df.apply(lambda row: inter_function_inc(row.hours_after_jan_2020, row.sp_lat, row.sp_lon), axis=1)\n",
    "cygnss_df = filter_nan_smap(cygnss_df)\n",
    "\n",
    "inter_function_vo = interpolate(smap_df, 'vegetation_opacity', 'lat', 'long', 'time')\n",
    "cygnss_df['vegetation_opacity'] = cygnss_df.apply(lambda row: inter_function_vo(row.hours_after_jan_2020, row.sp_lat, row.sp_lon), axis=1)\n",
    "cygnss_df = filter_nan_smap(cygnss_df, target='vegetation_opacity')\n",
    "\n",
    "inter_function_surface_roughness = interpolate(smap_df, 'surface_roughness', 'lat', 'long', 'time')\n",
    "cygnss_df['surface_roughness'] = cygnss_df.apply(lambda row: inter_function_surface_roughness(row.hours_after_jan_2020, row.sp_lat, row.sp_lon), axis=1)\n",
    "cygnss_df = filter_nan_smap(cygnss_df, target='surface_roughness')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incidence angle\n",
    "for group in incidence_classes:\n",
    "\n",
    "    # Filter the target value\n",
    "    current_cygnss = cygnss_df[cygnss_df[target_val] >= group]\n",
    "    if not group == incidence_classes[len(incidence_classes) - 1]:\n",
    "        current_cygnss = current_cygnss[current_cygnss[target_val] < group + interval]\n",
    "\n",
    "    print('Processing values: ' + str(group) + ' to ' + str(group + interval) + '    Length of cygnss: ' + \n",
    "          str(len(current_cygnss)) + '    Current group: ' + str(group))\n",
    "    \n",
    "    corr = current_cygnss['sm'].corr(current_cygnss['sr'])\n",
    "    statistics_dict[group] = corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot incidence angle\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(list(statistics_dict.keys()), list(statistics_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vegetation Opacity\n",
    "target_val = 'vegetation_opacity'\n",
    "#      [  N     W      S      E  ]\n",
    "area = [27.2, 80.32, 21.81, 88.29]\n",
    "interval = 0.1\n",
    "min_value = 20\n",
    "max_value = 70\n",
    "classes = None\n",
    "fuzzy = False\n",
    "step_size = 5\n",
    "\n",
    "classes_100 = list(range(min_value, max_value, step_size))\n",
    "classes_vegetation_opacity = []\n",
    "for c in classes_100:\n",
    "    classes_vegetation_opacity.append(c/100)\n",
    "\n",
    "statistics_dict_vo = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in classes_vegetation_opacity:\n",
    "    current_cygnss = cygnss_df[cygnss_df[target_val] >= group]\n",
    "    if not group == classes_vegetation_opacity[len(classes_vegetation_opacity) - 1]:\n",
    "        current_cygnss = current_cygnss[current_cygnss[target_val] < group + interval]\n",
    "\n",
    "    print('Processing values: ' + str(group) + ' to ' + str(round(group + interval, 1)) + '    Length of cygnss: ' + \n",
    "          str(len(current_cygnss)))\n",
    "    \n",
    "    corr = current_cygnss['sm'].corr(current_cygnss['sr'])\n",
    "    statistics_dict_vo[group] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(list(statistics_dict_vo.keys()), list(statistics_dict_vo.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surface Roughness\n",
    "target_val = 'surface_roughness'\n",
    "#      [  N     W      S      E  ]\n",
    "area = [27.2, 80.32, 21.81, 88.29]\n",
    "min_value = smap_df['surface_roughness'].min()\n",
    "max_value = smap_df['surface_roughness'].max()\n",
    "bins = 20\n",
    "classes_surface_roughness = []\n",
    "fuzzy = False\n",
    "step_size = (max_value - min_value)/bins\n",
    "\n",
    "for i in range(bins):\n",
    "    classes_surface_roughness.append(min_value + i*step_size)\n",
    "\n",
    "statistics_dict_surface_roughness = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in classes_surface_roughness:\n",
    "    current_cygnss = cygnss_df[cygnss_df[target_val] >= group]\n",
    "    if not group == classes_surface_roughness[len(classes_surface_roughness) - 1]:\n",
    "        current_cygnss = current_cygnss[current_cygnss[target_val] < group + interval]\n",
    "\n",
    "    print('Processing values: ' + str(group) + ' to ' + str(round(group + interval, 1)) + '    Length of cygnss: ' + \n",
    "          str(len(current_cygnss)))\n",
    "    \n",
    "    corr = current_cygnss['sm'].corr(current_cygnss['sr'])\n",
    "    statistics_dict_surface_roughness[group] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "\n",
    "ax.plot(list(statistics_dict_surface_roughness.keys()), list(statistics_dict_surface_roughness.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}